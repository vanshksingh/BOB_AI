


## Ascendant AI Capabilities

<img width="1072" alt="Screenshot 2024-06-30 at 8 03 13 PM" src="https://github.com/vanshksingh/BOB_AI/assets/114809624/6ef785a1-fdde-484f-8c2e-79268d961a36">


Ascendant AI is a cutting-edge model designed to perform a wide range of tasks:

- **Calculations**: Handle complex addition, multiplication, and other mathematical operations.
- **Image Generation and Interpretation**: Create and analyze images with high precision.
- **Data Analysis**: Analyze and interpret complex data sets.
- **Task Prioritization**: Efficiently prioritize tasks to optimize workflow.
- **Full Web Access**: Retrieve and analyze information from the web in real-time.
- **RAG (Retrieval-Augmented Generation)**: Enhance responses with up-to-date information from various sources.
- **Python Environment (REPL)**: Execute and interact with Python code seamlessly.
- **Full Bash Command Line Access**: Execute and manage tasks using a complete bash command line interface.
- **Seamless Operation**: Works both online and offline, retaining context even after powering down.
- **Workflow Integration**: Integrates smoothly into various workflows, ensuring continuous and adaptive performance.


## Using Streamlit for Interactive Data Applications

To utilize Streamlit for creating interactive data applications, follow these steps to run `main.py`:

1. **Install Streamlit**: Ensure Streamlit is installed in your Python environment. You can install it using pip:
   ```
   pip install streamlit
   ```

2. **Create Your Application**: Write your application code in `main.py` using Streamlit's Python API. Here’s a simple example:

   ```python
   # main.py
   import streamlit as st

   def main():
       st.title('My Streamlit App')
       st.write('Hello, Streamlit!')

   if __name__ == '__main__':
       main()
   ```

3. **Run Your Application**: Open a terminal or command prompt, navigate to the directory containing `main.py`, and run Streamlit:
   ```
   streamlit run main.py
   ```

4. **View Your Application**: Streamlit will launch a local web server and open your default web browser to display your application. You can interact with the app and see changes in real-time as you modify the code in `main.py`.

Streamlit simplifies the process of building and deploying interactive data applications, making it easy to share insights and prototypes with others in the data science community.

### Library Brief

Brief description of major libraries used:

- **json**: A built-in Python library to parse and handle JSON data.
- **os**: Provides a way of using operating system-dependent functionality such as reading or writing to the file system.
- **datetime**: Supplies classes for manipulating dates and times.
- **streamlit**: An open-source app framework for Machine Learning and Data Science projects.
- **langchain_community.llms**: Contains modules like Ollama for handling large language models.
- **langchain_core.prompts**: Includes tools like ChatPromptTemplate and MessagesPlaceholder for creating dynamic prompts.
- **langchain_community.chat_message_histories**: Used for storing chat message history in Streamlit applications.
- **langchain_core.tools**: Contains tools like `tool` and `render_text_description` for various operations.
- **langchain_core.output_parsers**: Provides parsers like JsonOutputParser for handling outputs.
- **langchain_experimental.utilities**: Includes utilities like PythonREPL for executing Python code.
- **langchain_core.messages**: Contains classes like HumanMessage and AIMessage for handling messages.
- **langchain_google_genai**: Integrates with Google Generative AI for enhanced AI capabilities.
- **speech_recognition**: A library for performing speech recognition.
- **subprocess**: Allows spawning new processes, connecting to their input/output/error pipes, and obtaining their return codes.
- **time**: Provides various time-related functions.
- **gtts**: Google's Text-to-Speech API for converting text to speech.
- **platform**: Accesses underlying platform’s data, such as the OS name.
- **pathlib**: Object-oriented filesystem paths.
- **google.generativeai**: Google's library for generative AI capabilities.
- **transformers**: A library from Hugging Face for state-of-the-art Natural Language Processing.
- **PIL (Pillow)**: Python Imaging Library for opening, manipulating, and saving image files.
- **torch**: A deep learning framework by PyTorch.
- **cv2 (OpenCV)**: Open Source Computer Vision Library for real-time computer vision.
- **DuckDuckGoSearchRun**: A tool for searching information using DuckDuckGo.
- **langchain.agents**: Contains modules to load tools and agents.
- **OpenWeatherMapAPIWrapper**: A utility to interact with OpenWeatherMap API.
- **getpass**: Provides a way to handle password prompts where the input is not echoed.
- **bs4 (Beautiful Soup)**: A library for parsing HTML and XML documents.
- **langchain.hub**: A module for accessing Langchain's hub.
- **langchain_chroma**: Provides integration with Chroma for vector database management.
- **langchain_community.document_loaders**: Includes WebBaseLoader for loading web-based documents.
- **langchain_core.output_parsers**: Contains parsers like StrOutputParser for string outputs.
- **langchain_core.runnables**: Provides RunnablePassthrough for creating pass-through functions.
- **langchain_openai**: Integration with OpenAI’s embeddings.
- **langchain_text_splitters**: Offers tools like RecursiveCharacterTextSplitter for text splitting.
- **langchain_community.embeddings**: Includes OllamaEmbeddings for handling embeddings.
- **langchain_community.document_loaders**: Provides loaders like PyPDFLoader for PDF documents.
- **re**: The regular expressions library for string pattern matching.
- **generator**: Custom library for image generation.
- **glob**: Finds all the pathnames matching a specified pattern according to the rules used by the Unix shell.



## Code Explanation

### @tool Decorator

The `@tool` decorator enhances Python functions with additional capabilities within the Langchain framework. It allows functions like `add` to be integrated seamlessly into larger workflows, providing them with enhanced properties such as dynamic handling of inputs and outputs, integration with other tools and agents, and context management across various tasks.

```python
@tool
def add(first: int, second: int) -> int:
    "Add two integers."
    return first + second ```

As seen in the example, the add function is a typical Python function that simply adds two integers together. The @tool decorator extends its functionality beyond basic addition, enabling it to participate in more complex data processing and workflow scenarios.



## Langchain: Empowering Workflow Chains

Langchain facilitates the creation and management of dynamic workflow chains, allowing seamless integration of tools and agents. It enhances productivity by enabling the chaining of diverse functionalities, ensuring efficient data processing and interaction across various tasks.

```python
# Example of defining a tool chain in Langchain
def tool_chain(model_output):
    tool_map = {tool.name: tool for tool in tools}
    chosen_tool = tool_map[model_output["name"]]
    return itemgetter("arguments") | chosen_tool
```

In this example, `tool_chain` illustrates how Langchain enables the selection and execution of tools based on model output, streamlining complex workflows by passing arguments to chosen tools dynamically.



## OLLAMA: Empowering Language Models

OLLAMA (Open Language Learning Models Architecture) empowers language models within the Langchain ecosystem. It facilitates advanced natural language processing tasks by providing a robust framework for model integration, dynamic interaction, and seamless workflow management. OLLAMA enhances productivity by enabling sophisticated language-based operations and adaptive learning capabilities across diverse applications.

```python
# Example of using OLLAMA in Langchain
from langchain_community.llms import Ollama

# Initialize Ollama language model
ollama_model = Ollama()

# Example usage of Ollama for language processing
text_input = "Translate this text into Spanish."
translated_text = ollama_model.translate(text_input, target_language="es")
print(translated_text)
```

In this example, `ollama_model` demonstrates how OLLAMA integrates with Langchain to perform language processing tasks such as translation, showcasing its capabilities in enhancing language-based operations within workflow chains.


## Perchance: Custom Text-to-Image Tool

Perchance is a custom text-to-image tool developed for specific applications within the Langchain ecosystem. It allows for the generation of images from textual descriptions without relying on an external API. This approach ensures that the tool operates seamlessly within Langchain's environment, promoting creative content creation and visual representation with a Python-based DIY solution.


## Streamlit: Interactive Data Applications

Streamlit is a powerful framework for creating interactive data applications in Python. It simplifies the process of building and deploying web applications for data science and machine learning projects. Streamlit enables developers to quickly prototype and share their data insights through intuitive and customizable interfaces, making it a versatile tool for visualization and communication within the data science community.

## Retrieval-Augmented Generation (RAG) in Natural Language Processing

Retrieval-Augmented Generation (RAG) integrates retrieved knowledge with generative models to enhance the quality and relevance of outputs. Here’s a streamlined overview with examples:

### How RAG Works

1. **Retrieval**: Fetch relevant information from external sources based on input.
   
2. **Augmentation**: Integrate retrieved knowledge into the generative model.
   
3. **Generation**: Produce coherent and contextually enriched text or responses.

### Examples of RAG

- **Example 1: Question Answering**
  - **Input**: "What is the capital of France?"
  - **Retrieval**: Knowledge base lookup for capitals.
  - **Augmentation**: Incorporate retrieved answer ("Paris").
  - **Generation**: Output response ("The capital of France is Paris.").

- **Example 2: Creative Writing**
  - **Input**: "Write a short story about a haunted house."
  - **Retrieval**: Retrieve descriptions of haunted houses.
  - **Augmentation**: Blend retrieved narratives into story creation.
  - **Generation**: Output a unique short story combining retrieved and generated content.

### Benefits of RAG

- **Enhanced Relevance**: Improves output accuracy by integrating external knowledge.
- **Versatile Applications**: Applicable across tasks like question answering, summarization, and creative writing.
- **Improved Coherence**: Generates more contextually appropriate and coherent responses.

RAG represents a significant advancement in leveraging external knowledge to enrich and improve natural language generation tasks.

## Hugging Face Models for Offline Image Tasks

Hugging Face models excel in offline image tasks such as image summary, object classification, and detection:

- **Image Summary**: Generate concise descriptions of image content.
- **Object Classification**: Accurately categorize objects within images.
- **Object Detection**: Identify objects and their locations in images.

These models leverage advanced transformers for robust performance, making them versatile for various applications in image analysis and understanding.


## Addressing Challenges in Model Development

### Persistent Chat Issue

**Problem**: Persistent chat history was not possible due to synchronous working of Streamlit.

**Fix**: Implement a solution using JSON files to save chat history after each iteration, enabling the preservation of conversation context across sessions.

### Model Functionality Issue

**Problem**: The model did not effectively follow instructions or utilize tools as expected.

**Fix**: Use specific instructive models or adjust settings such as using JSON forced output and lowering temperature values to improve adherence and output quality.

### Offline Model Execution Issue

**Problem**: Models wouldn’t work offline.

**Fix**: Utilize Ollama to enable the execution of offline models.

### Vision Integration Issue

**Problem**: Couldn’t integrate vision capabilities offline.

**Fix**: Split basic tasks to Hugging Face offline transformers, such as summary generation for images and image classification.

### Integration with Gemini Issue

**Problem**: Couldn’t make vision work with Gemini.

**Fix**: Develop specific vision as a callable tool to integrate seamlessly with Gemini.

### Front-End Development Challenge

**Problem**: Hard to develop a front-end in a short time.

**Fix**: Utilize Streamlit for rapid development and easy deployment of user interfaces.

### Perchance Image Generation Issue

**Problem**: Perchance image generation uses asynchronously found keys, which conflicts with Streamlit's synchronous operation.

**Fix**: Rewrite the key-finding algorithm to synchronize with Streamlit's operational model.

### Choosing Between Offline and Online Models

**Problem**: Uncertain when to use offline or online models.

**Fix**: Implement a ping check to determine network availability; use Gemini if available, otherwise use Mistral.

### Performance Feedback Issue

**Problem**: Offline mode is slow, and users perceive the app has crashed.

**Fix**: Add a progress bar to indicate execution stages and provide real-time feedback.

### System-Level Access Issue

**Problem**: Can’t access system-level functions due to protection.

**Fix**: Utilize bash shell terminal to execute commands, open apps, set timers, and run bash code.

### Weak Math Capabilities of Language Models

**Problem**: Language model's math abilities are limited.

**Fix**: Use Repel for enhancing mathematical capabilities and for other tasks.

### Improving AI Responsiveness

**Problem**: AI responses feel inadequate.

**Fix**: Implement context awareness to enable the model to reference previous interactions, enhancing response quality.

### Handling Sensitive Data in Queries

**Problem**: Personal data in questions is sensitive.

**Fix**: Use Retrieval-Augmented Generation (RAG) to ensure responses are highly specific and appropriate when handling sensitive queries.





## Future Work and Enhancements

### Enhancing Database Query Capabilities

**Goal**: Integrate SQL query commands to enable more complex database queries.

### Self-Referencing and Recursive Functionality

**Goal**: Enable the model to pass tool outputs back to itself or call itself recursively for iterative tasks.

### Seamless Code Execution

**Goal**: Enhance the capability to execute code in a larger prompt without execution pauses or limitations.

### Expanding Data Loaders

**Goal**: Add additional loaders (e.g., mail, file system) to provide more opportunities for Retrieval-Augmented Generation (RAG).

### Persistent Embedding for RAG

**Goal**: Implement a mechanism to store RAG embeddings permanently or in an SQL-type database for faster retrieval and improved efficiency.

### State-of-the-Art Offline Solution

**Goal**: Develop the model into a state-of-the-art offline solution for home automation and diverse applications.

### Integration with Home Sensors

**Goal**: Enable connectivity to home sensors to gather real-time data for improved contextual understanding and decision-making.

### Messaging and Document Generation Capabilities

**Goal**: Integrate functionalities to send messages on WhatsApp and other platforms, and enable document writing and output.

These enhancements aim to expand the model's capabilities, making it more versatile, efficient, and suitable for a wider range of practical applications.



## Conclusion

This README document outlines the capabilities, challenges, and future enhancements of the AI model developed. By addressing various issues and continually improving functionalities, the model aims to provide robust solutions in natural language processing, image analysis, and interactive applications. As we continue to evolve and enhance its capabilities, feedback and contributions are welcomed to further refine and expand its utility across different domains and use cases.

---

**Author:**  
Vansh Kumar Singh

Pranshu Gautam

**Acknowledgement:**  
All libraries and referenced code belong to their respective original owners and are used in the spirit of open source.

